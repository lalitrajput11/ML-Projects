{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w = weight , b = biased\n",
    "\n",
    "Kernal Function : Linear , Polynomial, RBF FUNCTION(Radial basis function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>202.935536</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>226.655537</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>263.964248</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>242.864034</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>262.717340</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K  temperature   humidity        ph    rainfall label\n",
       "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
       "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
       "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
       "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
       "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/home/lalitrajput/Downloads/Duact/Crop_recommendation.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) are a powerful supervised learning algorithm used primarily for classification tasks, but they can also be applied to regression problems. Hereâ€™s a detailed overview of SVM, including when to apply it and other important considerations.\n",
    "\n",
    "What is SVM?\n",
    "\n",
    "Basic Concept: SVM works by finding the hyperplane that best separates data points of different classes in a high-dimensional space. The goal is to maximize the margin between the closest points of the classes (support vectors) and the hyperplane.\n",
    "Support Vectors: These are the data points that are closest to the hyperplane and are critical in defining the position and orientation of the hyperplane. They have the most influence on the model.\n",
    "\n",
    "Key Features of SVM\n",
    "\n",
    "Kernel Trick: SVM can use different kernel functions (linear, polynomial, radial basis function (RBF), etc.) to transform the input space into a higher-dimensional space where it may be easier to find a separating hyperplane.\n",
    "Regularization: SVM includes a regularization parameter (C) that controls the trade-off between maximizing the margin and minimizing classification error. A small C value allows for a larger margin at the cost of some misclassifications, while a large C value tries to classify all training examples correctly.\n",
    "Soft Margin: SVM can handle noisy data by introducing slack variables, which allow for some misclassifications\n",
    "\n",
    "When to Apply SVM\n",
    "\n",
    "Linearly Separable Data: SVM is effective when the data is linearly separable or can be transformed into a linearly separable space using kernel functions.\n",
    "High Dimensional Data: SVM performs well in high-dimensional spaces, making it suitable for text classification and bioinformatics.\n",
    "\n",
    "Binary Classification: While SVM can be adapted for multi-class classification (using strategies like one-vs-one or one-vs-all), it is inherently designed for binary classification tasks.\n",
    "Outlier Sensitivity: SVM is less sensitive to outliers compared to some other algorithms, as it focuses on the support vectors.\n",
    "\n",
    "Important Considerations\n",
    "\n",
    "Choice of Kernel: The choice of kernel can significantly impact the performance of the SVM model. Experimenting with different kernels is often necessary to find the best fit for your data.\n",
    "Parameter Tuning: Parameters like C (regularization) and kernel-specific parameters (e.g., gamma for RBF) need to be carefully tuned, often using techniques like grid search or cross-validation.\n",
    "Computational Complexity: SVM can be computationally intensive, especially with large datasets, as the training time can increase quadratically with the number of samples.\n",
    "Interpretability: SVM models can be less interpretable than simpler models like logistic regression, especially in non-linear cases.\n",
    "Overfitting: SVM can suffer from overfitting, especially when the regularization parameter is too small\n",
    "\n",
    "Summary\n",
    "\n",
    "Use SVM when you have a classification problem with high-dimensional data, especially if the data is not linearly separable or if you suspect complex relationships between features.\n",
    "Considerations include kernel selection, parameter tuning, and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# ss = StandardScaler()\n",
    "\n",
    "# data.iloc[:,:-1]=ss.fit_transform(data.iloc[:,:-1])\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9727272727272728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "clf = SVC()  \n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS SVC : by default  < its kernal is at rbf>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9848484848484849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel=\"linear\")  \n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787878787878788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "clf = SVC(kernel='poly',)  \n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
